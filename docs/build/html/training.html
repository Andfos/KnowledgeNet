<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>training module &mdash; KnowledgeNet 0.0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=f6245a2f"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="utils module" href="utils.html" />
    <link rel="prev" title="plots module" href="plots.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            KnowledgeNet
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="intro.html#related-works">Related Works</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">knowledge-net</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="config.html">config module</a></li>
<li class="toctree-l2"><a class="reference internal" href="main.html">main module</a></li>
<li class="toctree-l2"><a class="reference internal" href="networks.html">networks module</a></li>
<li class="toctree-l2"><a class="reference internal" href="plots.html">plots module</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">training module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#training.check_network"><code class="docutils literal notranslate"><span class="pre">check_network()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#training.get_accuracy"><code class="docutils literal notranslate"><span class="pre">get_accuracy()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#training.get_loss"><code class="docutils literal notranslate"><span class="pre">get_loss()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#training.prune_network"><code class="docutils literal notranslate"><span class="pre">prune_network()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#training.sparse_group_lasso"><code class="docutils literal notranslate"><span class="pre">sparse_group_lasso()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#training.train_network"><code class="docutils literal notranslate"><span class="pre">train_network()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">utils module</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">KnowledgeNet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="modules.html">knowledge-net</a></li>
      <li class="breadcrumb-item active">training module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/training.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-training">
<span id="training-module"></span><h1>training module<a class="headerlink" href="#module-training" title="Permalink to this heading"></a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="training.check_network">
<span class="sig-prename descclassname"><span class="pre">training.</span></span><span class="sig-name descname"><span class="pre">check_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dG_init</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_cols</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#training.check_network" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="training.get_accuracy">
<span class="sig-prename descclassname"><span class="pre">training.</span></span><span class="sig-name descname"><span class="pre">get_accuracy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truth</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preds</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#training.get_accuracy" title="Permalink to this definition"></a></dt>
<dd><p>Calculate the accuracy of model predictions.</p>
<p>This function computes the accuracy of a machine learning model’s predictions
given the ground truth labels. It is designed to handle both softmax and
sigmoid output activations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – An instance of your machine learning model class.</p></li>
<li><p><strong>truth</strong> (<em>tf.Tensor</em>) – An tensor containing the ground truth labels.</p></li>
<li><p><strong>preds</strong> (<em>tf.Tensor</em>) – An tensor containing the model’s predictions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>accuracy</strong> – The accuracy of the model’s predictions, represented as a decimal value
between 0.0 and 1.0.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="training.get_loss">
<span class="sig-prename descclassname"><span class="pre">training.</span></span><span class="sig-name descname"><span class="pre">get_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_true</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y_pred</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reg_penalty</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#training.get_loss" title="Permalink to this definition"></a></dt>
<dd><p>Calculate the total loss for a given model’s predictions.</p>
<p>This function computes the total loss, which consists of the prediction loss
and optionally includes a regularization penalty, if specified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – The neural network model for which to calculate the loss.</p></li>
<li><p><strong>y_true</strong> (<em>tf.Tensor</em>) – The true target values.</p></li>
<li><p><strong>y_pred</strong> (<em>tf.Tensor</em>) – The predicted values generated by the model.</p></li>
<li><p><strong>reg_penalty</strong> (<em>bool</em><em>, </em><em>optional</em>) – A flag indicating whether to include regularization penalties in the loss.
If True (default), the regularization loss, if defined in the model’s layers,
will be added to the total loss. If False, only the prediction loss is
considered.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>loss</strong> – The total loss, which can include both the prediction loss and regularization
penalties, if enabled.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="training.prune_network">
<span class="sig-prename descclassname"><span class="pre">training.</span></span><span class="sig-name descname"><span class="pre">prune_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prune_epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gl_pen1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l0_pen1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gl_pen2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l0_pen2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#training.prune_network" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="training.sparse_group_lasso">
<span class="sig-prename descclassname"><span class="pre">training.</span></span><span class="sig-name descname"><span class="pre">sparse_group_lasso</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">w</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamb1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamb2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eta2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#training.sparse_group_lasso" title="Permalink to this definition"></a></dt>
<dd><p>Apply Sparse Group Lasso regularization to a given weight matrix.</p>
<p>This function updates the input weight matrix ‘w’ by inducing sparsity
both within columns and within rows based on specified regularization
parameters (lamb1, eta1, lamb2, eta2).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>w</strong> (<em>tf.Tensor</em>) – The input weight matrix to be regularized.</p></li>
<li><p><strong>lamb1</strong> (<em>float</em>) – The group lasso regularization strength for inducing sparsity of
columns.</p></li>
<li><p><strong>eta1</strong> (<em>float</em>) – The l0 penalty applied to induce sparsity within columns.</p></li>
<li><p><strong>lamb2</strong> (<em>float</em>) – The group lasso regularization strength for inducing sparsity of
rows.</p></li>
<li><p><strong>eta2</strong> (<em>float</em>) – The l0 penalty applied to induce sparsity within rows.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The updated weight matrix after applying Sparse Group Lasso regularization.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<dl class="simple">
<dt>This function considers two types of regularization:</dt><dd><ol class="arabic simple">
<li><p>Column sparsity: Each column is the set of all weights incoming to a
neuron. It encourages certain columns to contain
all zeros (controlled by lamb1) or some zeros (controlled by
eta1).</p></li>
<li><p>Row sparsity: Each row is the set of all weights outgoing from a
neuron. It encourages certain rows to contain all
zeros (controlled by lamb2) or some zeros (controlled by eta2).</p></li>
</ol>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lamb1</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eta1</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lamb2</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">eta2</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">updated_w</span> <span class="o">=</span> <span class="n">sparse_group_lasso</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">lamb1</span><span class="p">,</span> <span class="n">eta1</span><span class="p">,</span> <span class="n">lamb2</span><span class="p">,</span> <span class="n">eta2</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="training.train_network">
<span class="sig-prename descclassname"><span class="pre">training.</span></span><span class="sig-name descname"><span class="pre">train_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classification</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#training.train_network" title="Permalink to this definition"></a></dt>
<dd><p>Train a machine learning model using a given dataset and optimizer.</p>
<p>This function performs model training for a specified number of epochs using
the provided training dataset and optimizer. It includes forward and backward
passes, gradient computation, weight updates, and optional accuracy monitoring
for classification tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – The machine learning model to be trained.</p></li>
<li><p><strong>train_dataset</strong> (<em>tf.data.Dataset</em>) – The training dataset, typically created using TensorFlow data pipeline
utilities.</p></li>
<li><p><strong>train_epochs</strong> (<em>int</em>) – The number of training epochs (complete passes through the training dataset).</p></li>
<li><p><strong>optimizer</strong> (<em>tf.keras.optimizers.Optimizer</em>) – The optimization algorithm used for weight updates during training.</p></li>
<li><p><strong>classification</strong> (<em>bool</em><em>, </em><em>optional</em>) – A flag indicating whether the task is classification (True) or not (False).
If True (default), the function monitors and prints accuracy during training.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>model</strong> – The trained machine learning model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.keras.Model</p>
</dd>
</dl>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="plots.html" class="btn btn-neutral float-left" title="plots module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="utils.html" class="btn btn-neutral float-right" title="utils module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Andrew Foster.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>